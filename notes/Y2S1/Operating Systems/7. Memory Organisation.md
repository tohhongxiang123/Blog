# Memory Organisation

We need to find a way to bind code and data to memory

- Address binding, logical vs physical address space

Contiguous allocation

- Fixed vs dynamic partitioning, fragmentation

Paging

- Address translation, page table implementation, shared pages, 2-level page table, inverted page table

Segmentation

- Address translation

# Binding Code and Data to Memory

To run a program, a process image must be created and loaded into memory

![](https://media.geeksforgeeks.org/wp-content/uploads/memoryLayoutC.jpg)

Each program has the following

- Text: Where the code of the program is stored
- Data: Where the global parameters for the program is stored
- Heap: Where dynamically allocated variables are stored
- Stack: Where parameters and local variables in a function are stored

A compiler is used to translate source code to object code. A linker is used to combine object modules to resolve references. A loader is used to create the process image, allocate memory for the process, and load process image into the allocated memory

![](https://media.geeksforgeeks.org/wp-content/uploads/20200808221828/llgfg.png)

Address binding of instructions and data to memory addresses can happen in 3 different stages

1. Compile time: If memory location known a priori, absolute code can be generated (using absolute addresses); must recompile if starting location changes
2. Load time: Compiler generates relocatable code (using addresses relative to the start register), and binding is performed by the loader
3. Execution time: If the process can be moved during its execution from one memory segment to another, binding is delayed until runtime

In compile-time or load-time binding, **absolute address format** is used in process image

- Binding of logical address space to the physical memory is static
- Once process image is loaded, it cannot be moved in memory
- If address generated by CPU < base OR >= base + limit, then an error is thrown
- Otherwise, memory address = address generated by the CPU

However in execution-time binding, since we only know the address of the program in memory at execution time, we use **relative address format**

- Addresses tell you how far relative to the start register to go to
- If address generated by CPU >= limit, an error is thrown
- Otherwise, memory address = address generated by CPU + base register address

# Logical vs Physical Address Space

- Address space: All addresses accessible by a process
  - The range of addresses along a street
- Logical address: Addresses used in the code, generated by the CPU when executing an instruction
  - What you see when you want to navigate to a house, can be "5th house from the start" (relative), or "Block 1234" (absolute)
- Physical address: Address used to access physical memory, seen by the memory unit
  - The actual address of the house itself

# Allocating Memory Among Processes

![](https://media.geeksforgeeks.org/wp-content/uploads/20200405213343/Picture12.jpg)
![](https://media.geeksforgeeks.org/wp-content/uploads/20200405214155/Picture24.jpg)

There are 2 approaches to allocating memory

1. Contiguous Allocation: Logical address space of a process remains contiguous in physical memory
   - Fixed partitioning
   - Dynamic partitioning
2. Non-contiguous allocation: A process logical address space is scattered over different regions in physical memory
   - Paging

## Contiguous Allocation

In contiguous allocation, logical address space of a process maps to a contiguous space in physical memory (the memory remains together, unscattered)

### Fixed Partitioning

Memory is partitioned into regions with fixed boundaries before executing the program. When the program requires memory, it takes memory from a partition.

- The number of partitions in memory is fixed
- The size of each partition may or may not be the same
- When memory is allocated, the entire partition is allocated to the code, regardless of how little of the partition was used
- No spanning is allowed
  - Spanning is when a single process spans across different spaces in main memory in non-consecutive order

Advantages of fixed partitioning

- Easy to implement
  - Simply requires putting a process into a certain partition without focusing on the emergence of internal or external fragmentation
- Little OS overhead
  - Requires lesser excess and indirect computational power

Disadvantages of fixed partitioning

- Internal fragmentation
  - Main memory use is inefficient. Any program, regardless of size, occupies an entire partition. This can cause internal fragmentation
- External fragmentation
  - Total unused space of various partitions cannot be used to load the processes, even though there is space available, but not in contiguous form, since spanning is not allowed

### Dynamic Partitioning

When a process arrives, it is allocated memory from a hole large enough to accomodate it

- A hole is a block of available memory; holes of various sizes are scattered throughout memory
- OS maintains information about
  - Allocated partitions
  - Free partitions (holes)

There are multiple ways to allocate storage when using dynamic partitioning

- First-fit
  - Allocate the first hole that is big enough for the process
- Best-fit
  - Allocate the smallest hole that is big enough
  - Must search the entire list first, unless ordered by size
  - Produces smallest leftover hole
- Worst-fit
  - Allocate the largest hole
  - Must search entire list first, unless ordered by size
  - Produces largest leftover hole

Advantages of Dynamic partitioning

- No internal fragmentation
  - Given the fact that partitions in dynamic partitioning are created according to the needs of the process, there will not be any internal fragmentation due to not being any unused space in the partition
- No limitation on process size
  - For fixed partitioning, processes must be smaller than the largest partition, or else they will not be able to execute. In dynamic partitioning, process size is not restricted because partition size is determined according to process size
- Degree of multiprogramming is dynamic
  - Due to absence of internal fragmentation, there will not be unused space in the partition hence more processes can be loaded in the memory at the same time

Disadvantages of dynamic partitioning

- External fragmentation
  - Dynamic partition just allocates memory to processes directly without worrying about how the processes are stored in relation to one another. Hence external fragmentation can still occur
- Complex memory allocation
  - Allocation and deallocation of memory is complex since partition sizes will always keep changing. OS has to keep track of all partitions

#### Fragmentation

There are 2 types of fragmentation

![Internal vs External Fragmentation](https://i.stack.imgur.com/dSWgj.gif)

1. External fragmentation
   - There is enough total memory space to satisfy a request, however it is not contiguous. Happens outside a partition
2. Internal fragmentation
   - Allocated memory may be slightly larger than requested memory
   - This size difference is memory internal to a partition, but not being used

We can reduce external fragmentation by compaction

- Shuffle memory contents to place free memory together into one large block
- Compaction is possible only if relocatable address format is used in process image, and binding is done during execution time

![Compaction](https://exploringbits.com/wp-content/uploads/2021/01/Compaction-in-operating-system.png)

## Non-Contiguous Allocation

In non-contiguous allocation, even if the logical addresses are consecutive, that does not mean that the physical memories that those logical addresses are mapped to are consecutive as well.

We will look at 2 techniques of non-contiguous allocation

- Paging
- Segmentation

### Paging

![Paging](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_01_VirtualMemoryLarger.jpg)

- Physical memory is allocated to a process whenever physical memory is available
- In paging, physical memory is divided into fixed-sized blocks called **frames** (size is a power of 2, usually between 512 and 8192 bytes)
- Divide logical memory into blocks of the same size called **pages**
- OS keeps track of all free (unallocated) frames
- To run a program of size n pages, need to find n free frames, and load the program
- Set up a **page table** to translate logical to physical addresses
- This eliminates external fragmentation
- Internal fragmentation is still possible because processes may not be as big as a page

#### Address Translation Scheme

Logical address contains

1. Page number (p) - used as an index into a page table entry which contains the frame number in physical memory
2. Page offset (d) - combined with frame number to define the physical memory address that is sent to the memory unit

E.g.

CPU generates a logical address 1011 0010, where each page is $2^4 = 16$ bytes.

1. The logical address is split into 2 parts
   - Page index: 1011
   - Offset: 0010
   - Since each page is $2^4$ bytes, there are $2^4$ possible addresses on a single page. Hence the offset is $4$ bits
   - The page index is represented by the remainder of the bits in the logical address
2. The page index is used to check the page table, and see which address in physical memory the logical address was mapped to
   - Since the page index has 4 bits, there are actually $2^4 = 16$ page entries
3. The physical address is concatenated with the offset to find the overall address in physical memory to look for the information required

#### Implementation of Page Table

- Page table is kept in physical memory
- Page-table base register (PTBR) points to the page table (for each process)
- Page-table length register (PTLR) indicates the size of the page table
- In this scheme, every data/instruction access requires 2 memory accesses: one for page table, one for the data/instruction
  - Effective memory access time = $w \mu$, where each memory cycle access time is $\mu$ time units
- Memory access time can be reduced by the use of a special fast-lookup hardware cache called **associative registers** or **translation look-aside buffers** (TLBs)

![Page table with TLB](https://media.geeksforgeeks.org/wp-content/uploads/20190225192626/tlb1.jpg)

1. CPU generates logical address to retrieve data from
2. Check TLB to see if entry is within TLB
   1. If page is in TLB, we can immediately load the physical address
   2. If page is not in TLB, we hit the page table
   3. We can now load the physical address, and update the TLB with the new entry

#### Effective Access Time

Effective access time is the average time it takes to get a value from memory.

Consider that the time to lookup the TLB is $\epsilon$ time units, while a memory cycle time is $\mu$ units. The hit ratio ($\alpha$) is defined as the percentage of times that a page number is found in the associative registers

The effective access time (EAT) is

$$
(\mu + \epsilon) \alpha + (2 \mu + \epsilon) (1 - \alpha) = (2 - \alpha) \mu + \epsilon
$$

For $\alpha$ of the time, we only hit the TLB and retrieve from memory, hence $(\mu + \epsilon) \alpha$. For the remaining $1-\alpha$ times, we hit the TLB ($\epsilon$), and then have to hit the page table ($\mu$) which is in the physical memory, and then we retrieve the data ($\mu$). Hence $(2 \mu + \epsilon)(1-\alpha)$.

#### Shared Pages

Multiple processes can share the same physical memory. For these shared memories, the page table for each process will simply map the logical address for each process to the same space in physical memory

#### Multi-Level Page-Table Scheme

A logical address (on a 32bit machine with 4K page size) is divided into

- A page offset of 12 bits ($2^{12} = 4096$)
- A page number of 20 bits

The total number of page entries is $2^{20}$. Since each entry is 4 bytes (32 bits), each page table occupies $(2^{20} * 4) / (2^{20}) = 4MB$ of memory. A large page table is divided up to be easier to allocate in physical memoyr, with a small increase in effective access time

![](https://i.stack.imgur.com/8w9Uq.jpg)

Consider a page table for a 32 bit machine with 4K pages. We want to address 4GB ($2^{30} * 4 = 2^{32}$ bytes) of user address space

- When we split the user address space into pages, we will require $2^{32} / 2^{12} = 2^{20}$ entries within the outer page table
- Each entry in this page table is 32 bits (4 bytes) because we require 32 bits (4 bytes) per entry because we are on a 32 bit system
- The overall page table is $4 * 2^{20} = 2^{22}$ bytes large (4MB)
- Now we split up the page table itself into pages. Since each page is $2^{12}$ bytes, the number of pages is $2^{22} / 2^{12} = 2^{10}$
- There are now $2^{10}$ entries in the inner table, and each entry is again 4 bytes. This inner table is now $2^{10} * 4$ bytes, which is 4 KB

Since the page table is paged, the page number is further divided into

- $p_1$, an index into the outer page (second level) table
  - Since the outer table contains $2^{10}$ entries per page, requires 10 bits of data
- $p_2$, an index into the inner page (first level) table
  - Inner table contains $2^{10}$ entries, requires 10 bits of data

Thus a logical address is as follows

$$
\underbrace{\overbrace{p_1}^{10} \overbrace{p_2}^{10}}_\text{page number} \underbrace{\overbrace{d}^{12}}_\text{page offset}
$$

To find the physical memory address from the logical address

- We take $p_1$ from the logical address, and use it to index into the outer page table. This tells us which page table to look at next
- We use $p_2$ to index into the second table. This tells us which page in physical memory to use
- Now combining the address of the physical memory page, and the remaining offset ($d$) in the logical address, we now have the address of the physical memory we want to access

#### Inverted Page Table

![](https://www.techtud.com/sites/default/files/public/user_files/tud49672/invrted_0.gif)

Usually, each process has its own page table. Hence the system could have many page tables, consuming substantial memory space

- The page table size is proportional to that of the logical address space

An alternative is to have a single table with one entry for each physical frame, as <process-id, page-no>. This is an **Inverted Page Table**

- Logical address: <process-id, page-no, offset>
- Increases search time because table sorted by physical address, but lookups occur on logical address
- To access memory, the pair <process-id, page-no> is presented to inverted page table to find a match
- If match is found, say at entry i, the physical address <i, offset> is obtained

In an inverted page table, the number of entries is equal to the number of frames in the main memory.

In a normal page table, there is always space reserved for a page regardless of the whether the page is actually present in main memory or not. However, this is simply a waste of memory if the page is not present.

For process P1,

| Page | Frame |
| ---- | ----- |
| 0    | X     |
| 1    | X     |
| 2    | F1    |
| 3    | F3    |
| 4    | F6    |
| 5    | X     |
| 6    | F5    |

For process P2,

| Page | Frame |
| ---- | ----- |
| 0    | F2    |
| 1    | F4    |
| 2    | F7    |
| 3    | X     |
| 4    | X     |
| 5    | X     |
| 6    | F0    |

The X's denote frames that are not present in main memory. As you can see, there is a wastage of space. So what we can do instead is invert the page table. We can save the details only for the pages which are present in the main memory. Frames are the indices and the information saved inside the block will be the process ID and page number

| Page | Frame |
| ---- | ----- |
| 0    | OS    |
| 1    | P1 p2 |
| 2    | P2 p0 |
| 3    | P1 p3 |
| 4    | P2 p1 |
| 5    | P1 p6 |
| 6    | P1 p4 |
| 7    | P2 p2 |

Lets say if process 2 wants information on page 1. From the normal page table, we would go to the page table for P2, and then go to page 1, and see that the data is located in frame 4

For the inverted table, we go down the list, and check which entry is for `P2 p1`. That is the 4th entry. So we know that the data is located in frame 4.

### Segmentation

![](https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2016/02/segmentation.png)

- A memory-management scheme that breaks programs up into its logical segments, and allocating space for these segments into memory separately
- Unlike pages, segments can be of variable size
- A process has a collection of segments
- Like pages of a process, segments of a process may not be allocated contiguously

#### Address Translation

- Each segment has a segment no. and offset, i.e. the logical address is _<segment-no, offset>_
- Segment table: Each table entry has
  - Base: contains the starting physical address where the segments reside in memory
  - Limit: specifies the length of the segment
- Segment-table base register (STBR) points to the segment table's location in memory
- Segment-table length register (STLR) indicates number of segments used by a program

The procedure for address translation for segmentation

![Procedure for address translation for segmentation](https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2016/02/Translation.png)

1. Given segment number (s), find the corresponding entry in the segment table
2. Check that d < limit (if d > limit, it means that we want to access memory outside of the segment's allocated memory)
   1. If d > limit, we trap due to addressing error
3. We take the base register, and add the offset to find our physical memory's address

#### Fragmentation in Segmentation

- Since segments vary in length, memory allocation is a dynamic storage-allocation problem. Usually we use best-fit or first-fit
- Suffer from external fragmentation as process leaves the system, its occupied segments become holes in the memory
- As a process leaves the system, its occupied segments become holes of varying sizes in the memory

# Summary

Programs must be brought into memory for execution. We must solve the problem of allocating memory to processes

- Contiguous allocation
  - Fixed partitioning vs Dynamic partitioning
- Non-contiguous allocation
  - Paging vs Segmentation
- Fragmentation problems

Processes execute in its own logical address space, but the actual code and data are stored in physical memory. We must find a way to map logical addresses to physical addresses

- Paging
  - Basic scheme
  - Using translation lookaside buffers
  - Double/Multi-level paging
  - Inverted page tables
- Segmentation

# Resources

- https://www.geeksforgeeks.org/fixed-or-static-partitioning-in-operating-system/
- https://stackoverflow.com/questions/1200694/internal-and-external-fragmentation
- https://stackoverflow.com/questions/16323890/calculating-page-table-size
- https://youtu.be/Z4kSOv49GNc
- https://www.geeksforgeeks.org/segmentation-in-operating-system/
