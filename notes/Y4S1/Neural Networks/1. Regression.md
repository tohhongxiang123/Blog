# Regression

Primarily, neural networks are used to predict outputs labels from input features. Prediction tasks can be labelled into 2 categories:
1. Regression: Labels are continuous (Predicting age, weight, height etc)
2. Classification: Labels are discrete (Predicting gender, digits, flower types etc)

Training finds network weights and biases that are optimal for the prediction of labels from features

# Linear Neuron

The synaptic input $u$ to a neuron is given by 

$$
u = w^T x + b
$$

- $w = [w_1, ..., w_n]^T$ is the weights vector
- $x = [x_1, ..., x_n]^T$ is the inputs from the previous neurons
- $b$ is the bias

A linear neuron has a linear activation function

$$
y = f(u) = u
$$

## Linear Neurons Perform Linear Regression

Representing a dependent (output) variable as a linear combination of independent (input) variables is known as **linear regression**

The output of a linear neuron can be written as

$$
y = w_1 x_1 + ... + w_n x_n + b = \left( \sum_{i = 1}^{n} w_i x_i \right) + b
$$
- The weights and biases act as regression coefficients

Given training examples $\{\bold{x}_p, d_p\}_{p = 1}^{P}$ where $\bold{x}_p \in \mathbb{R}^n$ and target $d_p \in \mathbb{R}$, training a linear neuron finds a linear mapping $\phi: \mathbb{R}^n \to \mathbb{R}$ given by 

$$
y = \bold{w}^T \bold{x} + b
$$

## Stochastic Gradient Descent (SGD) for a Linear Neuron

Stochastic: Random

The cost function $J$ for regression is usually given as the square error between the neuron output and the target

Given a training pattern $(\bold{x}, d)$ we define $J$ as:

$$
J = \frac{1}{2} (d - y)^2
$$

- Note: We add a $\frac{1}{2}$ in front to remove coefficients when differentiating
- $y$ is the output from the neuron, while $d$ is the actual label

Now, using these equations:

$$
\begin{align*}
J &= \frac{1}{2} (d - y)^2 \\
y &= u = \bold{w}^T \bold{x} + b \\
\end{align*}
$$

We want to find $\nabla_\bold{w} J$ to minimise the error from the weights, 
$$
\begin{align*}
\frac{\partial J}{\partial y} &= -(d - y) \\
\nabla_\bold{w} J &= \frac{\partial J}{\partial \bold{w}} = \frac{\partial J}{\partial u} \frac{\partial u}{\partial \bold{w}}  \\
u &= \bold{w}^T x + b = \left( \sum_{i = 1}^{n} w_i x_i \right) + b \\
\frac{\partial u}{\partial \bold{w}} &= \begin{pmatrix} \frac{\partial u}{\partial \bold{w_1}} \\ \vdots \\ \frac{\partial u}{\partial \bold{w_n}} \end{pmatrix} = \begin{pmatrix} x_1 \\ \vdots \\ x_n \end{pmatrix} = \bold{x} \\
\end{align*}
$$

Hence, we get:

$$
\begin{align*}
\nabla_\bold{w} J = -(d - y) \bold{x}
\end{align*}
$$

Similarly, since $\frac{\partial u}{\partial b} = 1$,

$$
\nabla_b J = \frac{\partial J}{\partial u} \frac{\partial u}{\partial b} = -(d - y)
$$

For SGD, we update the weights based on the gradient we receive

$$
\begin{align*}
w &\leftarrow w - \alpha \nabla_\bold{w} J = \bold{w} + \alpha (d - y) \bold{x} \\
b &\leftarrow b - \alpha \nabla_b J = b + \alpha (d - y)
\end{align*}
$$

- $\alpha$ is the learning rate

## SGD Algorithm for Linear Neuron

Given a training set $\{ \bold{x}_p, d_p \}_{p = 1}^{P}$, we set a learning rate parameter $\alpha$. We initialize $\bold{w}$ and $b$ randomly. Then, we repeat until convergence:

For every training pattern $(\bold{x}_p, d_p)$:

$$
\begin{align*}
y_p &= \bold{w}^T \bold{x}_p + b \\
w &\leftarrow w + \alpha (d_p - y_p) x_p \\
b &\leftarrow b + \alpha (d_p - y_p)
\end{align*}
$$

# Gradient Descent (GD) for a Linear Neuron

Unlike stochastic gradient descent, we update the weights/biases after processing the whole batch of data

Given a training dataset $\{(\bold{x}_p, y_p)\}_{p=1}^{P}$, the cost function $J$ is given by the sum of square errors

$$
J = \frac{1}{2} \sum_{p = 1}^{P} (d_p - y_p)^2
$$

where $y_p$ is the neuron output for the input pattern $\bold{x}_p$

Then,

$$
\begin{align*}
\nabla_{\bold{w}} J &= \sum_{p = 1}^{P} \nabla_{\bold{w}} J_p \\
&= - \sum_{p = 1}^{P} (d_p - y_p) \bold{x}_p \\
&= - ((d_1 - y_1) \bold{x}_1 + ... + (d_P - y_P) \bold{x}_P) \\
&= -(\bold{x}_1 \cdots \bold{x}_P) \begin{pmatrix} (d_1 - y_1) \\ \vdots \\ (d_P - y_P) \end{pmatrix} \\
&= - \bold{X}^T (\bold{d} - \bold{y})
\end{align*}
$$

- $\bold{X} = \begin{pmatrix} \bold{x}_1^T \\ \vdots \\ \bold{x}_P^T \end{pmatrix}$ is the data matrix
- $\bold{d} = \begin{pmatrix} d_1 \\ \vdots \\ d_P \end{pmatrix}$ is the target vector
- $\bold{y} = \begin{pmatrix} y_1 \\ \vdots \\ y_P \end{pmatrix}$ is the output vector

Similarly, $\nabla_b J$ can be obtained by considering inputs of +1, and substituting a vector of +1 instead of $\bold{X}$

$$
\nabla_b J = -\bold{1}_P^T (\bold{d} - \bold{y})
$$

where $\bold{1} = \begin{pmatrix} 1 \\ \vdots \\ 1 \end{pmatrix} \in \mathbb{R}^P$

The output vector $y$ for the batch of $P$ patterns is given by:

$$
\bold{y} = \begin{pmatrix} y_1 \\ \vdots \\ y_P \end{pmatrix} 
= \begin{pmatrix} \bold{x}_1^T \bold{w} + b \\ \vdots \\ \bold{x}_P^T \bold{w} + b \end{pmatrix} = \begin{pmatrix} \bold{x}_1^T \\ \vdots \\ \bold{x}_P^T \end{pmatrix} \bold{w} + b \begin{pmatrix} 1 \\ \vdots \\ 1 \end{pmatrix} = \bold{X} \bold{w} + b \bold{1}_P
$$

Now, we can use the equations to find how to update $\bold{w}$ and $b$

$$
\begin{align*}
w &\leftarrow w - \alpha \nabla_\bold{w} J \\
b &\leftarrow b - \alpha \nabla_\bold{b} J
\end{align*}
$$

$$
\begin{align*}
w &\leftarrow w + \alpha \bold{X}^T (\bold{d} - \bold{y}) \\
b &\leftarrow b + \alpha \bold{1}_P^T (\bold{d} - \bold{y})
\end{align*}
$$

where $\bold{y} = \bold{X} \bold{w} + b \bold{1}_P$

## GD Algorithm for Linear Neuron

Given a training set $(\bold{X}, \bold{d})$, we set a learning parameter $\alpha$. We initialize $\bold{w}$ and $b$ randomly, then repeat until convergence:

$$
\begin{align*}
\bold{y} &= \bold{X} \bold{w} + b \bold{1}_P \\
\bold{w} &= \bold{w} + \alpha \bold{X}^T (\bold{d} - \bold{y}) \\
b &= b + \alpha \bold{1}_P^T (\bold{d} - \bold{y})
\end{align*}
$$

# GD vs SGD for Linear Neurons

\ | GD | SGD 
--- | --- | ---
Data points used per update | $(\bold{X}, \bold{d})$ | $(\bold{x}_P, d_p)$
Cost Function | $J = \frac{1}{2} \sum_{p = 1}^{P} (d_p - y_p)^2$ | $J = \frac{1}{2} (d_p - y_p)^2$
Output | $\bold{y} = \bold{Xw} + b \bold{1}_P$ | $y_p = \bold{x}_P^T \bold{w} + b$
Update weights | $\bold{w} \leftarrow \bold{w} + \alpha \bold{X}^T (\bold{d} - \bold{y})$ | $\bold{w} \leftarrow \bold{w} + \alpha (d_p - y_p) \bold{x}_p$
Update biases | $b \leftarrow b + \alpha \bold{1}_P^T (\bold{d} - \bold{y})$ | $b \leftarrow b + \alpha (d_p - y_p)$

# Perceptron

Perceptron is a neuron with a **sigmoid** activation function and has an output

$$
y = f(u) = \frac{1}{1 + e^{-u}}
$$

And $u = \bold{w}^T \bold{x} + b$

The square error is used as a cost function for learning. Perceptrons perform **non-linear regression** of inputs

## Minimising Cost Function for Perceptron

The cost function $J$ is given by

$$
J = \frac{1}{2} (d - y)^2
$$

where $y = f(u)$ and $u = \bold{w}^T \bold{x} + b$

The gradient with respect to the synaptic input

$$
\frac{\partial J}{\partial u} = \frac{\partial J}{\partial y} \frac{\partial y}{\partial u} = -(d - y) f'(u)
$$

We know that $\frac{\partial u}{\partial \bold{w}} = \bold{x}$ and $\frac{\partial u}{\partial b} = 1$

$$
\begin{align*}
\nabla_\bold{w} J &= \frac{\partial J}{\partial \bold{w}} = \frac{\partial J}{\partial u} \frac{\partial u}{\partial \bold{w}} = -(d - y) f'(u) \bold{x} \\
\nabla_b J &= \frac{\partial J}{\partial b} = \frac{\partial J}{\partial u} \frac{\partial u}{\partial b} = -(d - y)f'(u)
\end{align*}
$$

Gradient learning equations:

$$
\begin{align*}
\bold{w} &\leftarrow \bold{w} - \alpha \nabla_{\bold{w}} J \\
b &\leftarrow b - \alpha \nabla_b J
\end{align*}
$$

Substituting gradients:

$$
\begin{align*}
\bold{w} &\leftarrow \bold{w} + \alpha (d - y) f'(u) \bold{x}  \\
b &\leftarrow b + \alpha (d - y)f'(u)
\end{align*}
$$

## SGD Algorithm for Perceptron

Given a training set $\{(\bold{x}_p, d_p)\}_{p=1}^{P}$, set a learning parameter $\alpha$. Initialize $\bold{w}$ and $b$ randomly, then repeat until convergence:

For each training pattern $(\bold{x}_p, d_p)$:

$$
\begin{align*}
u_p &= \bold{w}^T \bold{x}_p + b \\
y_p &= f(u_p) = \frac{1}{1 + e^{-u_p}} \\
\bold{w} &\leftarrow \bold{w} + \alpha (d_p - y_p) f'(u_p) \bold{x}_p \\
b &\leftarrow b + \alpha (d_p - y_p) f'(u_p)
\end{align*}
$$

## GD Algorithm for Perceptron

Similarly for GD algorithm for linear neuron, we just need to include a $f'(u)$

$$
\begin{align*}
\nabla_{\bold{w}} J &= -\bold{X}^T (\bold{d} - \bold{y}) f'(\bold{u}) \\
\nabla_{b} J &= -\bold{1}_P^T (\bold{d} - \bold{y}) f'(\bold{u})
\end{align*}
$$

- $\bold{X} = \begin{pmatrix} \bold{x}_1^T \\ \vdots \\ \bold{x}_P^T \end{pmatrix}$
- $\bold{d} = \begin{pmatrix} d_1 \\ \vdots \\ d_P \end{pmatrix}$
- $\bold{y} = \begin{pmatrix} y_1 \\ \vdots \\ y_P \end{pmatrix}$
- $f'(\bold{u}) = \begin{pmatrix} f'(u_1) \\ \vdots \\ f'(u_p) \end{pmatrix}$

The gradient descent learning is given by

$$
\begin{align*}
\bold{w} &\leftarrow \bold{w} - \alpha \nabla_{\bold{w}} J \\
b &\leftarrow b - \alpha \nabla_{b} J
\end{align*}
$$

Substituting the above, we get

$$
\begin{align*}
\bold{w} &\leftarrow \bold{w} + \alpha \bold{X}^T (\bold{d} - \bold{y}) f'(\bold{u}) \\
b &\leftarrow b + \alpha \bold{1}_P^T (\bold{d} - \bold{y}) f'(\bold{u})
\end{align*}
$$

Given a training set $(\bold{X}, \bold{d})$, we set a learning parameter $\alpha$, and initialize $\bold{w}$ and $b$ randomly. Repeat until convergence:

$$
\begin{align*}
\bold{u} &= \bold{Xw} + b\bold{1}_P \\
\bold{y} &= f(\bold{u}) = \frac{1}{1 + e^{-u}} \\
\bold{w} &\leftarrow \bold{w} + \alpha \bold{X}^T (\bold{d} - \bold{y}) f'(\bold{u}) \\
b &\leftarrow b + \alpha \bold{1}_P^T (\bold{d} - \bold{y}) f'(\bold{u})
\end{align*}
$$

The derivative of the sigmoid function:

$$
\begin{align*}
f'(u) &= \frac{-1}{(1 + e^{-u})^2} \frac{d (e^{-u})}{d u} \\
&= \frac{e^{-u}}{(1 + e^{-u})^2} \\
&= \frac{1}{1 + e^{-u}} - \frac{1}{(1 + e^{-u})^2} \\
&= y(1 - y)
\end{align*}
$$

For the $\tanh$ activation function, we can easily find the derivative as well

$$
\begin{align*}
f(u) &= \frac{e^u - e^{-u}}{e^u + e^{-u}} \\
f'(u) &= \left( 1 - \frac{e^u - e^{-u}}{e^u + e^{-u}} \right) \\
&= 1 - y^2
\end{align*}
$$

# Classification

Classification is used to identify/distinguish classes or groups of objects
- E.g. identify males from females, rugby players from ballet dancers

Let us consider the problem of identifying rugby players from ballet dancers. We will use 2 distinctive features:
- Height
- Weight

Let $x_1$ denote height, and $x_2$ denote weight. Every individual is represented by a point $\bold{x} = (x_1, x_2)$ in the feature space

## Decision Boundary

Continue from slide 48