# CNN Part 2

# CNN Architectures

- As the years pass, CNNs get deeper, with more intricate and different connectivity structures
- Depth is the key to high classification accuracy

## AlexNet

![](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-22_at_6.35.45_PM.png)

- Split within image is split between 2 GPUs
- Trained for a week on 2 Nvidia GTX 580 3GB GPU
- 60 million parameters
- Input size 227x227x3
- 8 layers deep: 5 convolution and pooling layers, and 3 fully connected layers
- 96 kernel learned by first convolution layer, 48 learned by each GPU
- Escape from a few layers
  - ReLU nonlinearity for solving gradient vanishing
  - Data augmentation
  - Dropout
  - Outperformed all previous models on ILSVRC by 10%

## GoogLeNet

![](https://media.geeksforgeeks.org/wp-content/uploads/20200429201549/Inceptionv1_architecture.png)

- An important lesson: Go deeper
- Inception structures to reduce parameters
- Batch normalisation
  - Normalisation of the activation for each training mini-batch
  - Allows us to use much higher learning rates, and be less careful about initialisation

## VGG

![](https://raw.githubusercontent.com/blurred-machine/Data-Science/master/Deep%20Learning%20SOTA/img/network.png)

- Go deeper
- 140M parameters
- Now commonly used for computing perceptual loss

## ResNet

![](https://miro.medium.com/v2/resize:fit:1200/1*6hF97Upuqg_LdsqWY6n_wg.png)

- Escape from 100 layers
  - Residual learning: Drives the new layer to learn something different
    ![](https://d2l.ai/_images/resnet-block.svg)

# More on Convolution

- Spatial size: $(N - F + 2P) / S + 1$, for
  - $N$: Image dimension
  - $F$: Kernel dimension
  - $P$: Amount of padding
  - $S$: Stride
- Number of parameters: If we had $N$ $D \times F \times F$ kernels, we would have $N(DF^2 + 1)$ parameters
  - $DF^2$ weights per kernel
  - 1 bias per kernel
- How many multiplication operations?
  $$
  u(i, j) = \sum_{l = -a}^{a} \sum_{m = -b}^{b} x(i + l, j + m) w(l, m) + b
  $$
  - For a $D \times F \times F$ filter:
    - We have $DF^2$ multiplications
    - We have $DF^2 - 1$ additions
    - We add once more for the bias
    - Hence, for one channel we require $DF^2 + DF^2 - 1 + 1 = 2DF^2$
  - Recall that a $D_1 \times H_1 \times W_1$ image convolved with a filter of $D_2 \times D_1 \times F \times F$ produces a $D_2 \times H_2 \times W_2$ output
    - The number of FLOPs: $(2DF^2) (D_2 H_2 W_2)$
