# Optimisation

Before producing the final executable code, many code generators perform optimisations to make the code faster and more compact. There are 2 kinds of optimisations

1. Platform-independent optimisations: Applies for any target platform
2. Platform-specific optimisations: Only applies to a particular target platform

Here we only consider simple platform-independent optimisations. Such optimisations are usually implemented on intermediate representations like Jimple

# Static Analysis

- Optimisations need to be behavior-preserving: Optimised code should run faster/take less space but behave exactly the same as the original program
- An optimising compiler has to reason statically (without running code) about all possible behaviors of the program
- It follows from some basic results of computability theory that it is impossible to statically predict precisely the possible behaviors of a program
- So optimisers have to be conservative: Only apply an optimisation if we can be certain that it is behavior-preserving

Examples of optimisations performed by modern compilers

- Register allocation
- Common subexpression elimination: If an expression has already been evaluated, reuse its previously computed value
- Dead code detection: Remove code that cannot be executed
- Loop invariant code motion: Move computation outside of loop body
- Loop fusion: Combine 2 loops into 1
- Reduction in strength: Replace slow operations with faster operations
- Bounds check elimination: In java, if an array index can be shown to be in range, we do not need to check it at runtime
- Function inlining: Replace a call to a function by its function body
- Devirtualisation: Turn a virtual method call into a static one

## Intra-Procedural vs Inter-Procedural

- Many optimisations only concern the code within a single method or function, this is intra-procedural
- More ambitious optimisations try to optimise several methods/functions at once: this is inter-procedural or whole-program optimisations
- There is a similar distinction between intra-procedural static analylsis and inter-procedural static analysis
- Whole-program optimisations have the potential to deliver greater performance improvements, but they are more difficult to apply and it is harder to reason about their safety

# Intra-Procedural Analysis

## Control Flow Graphs

A control flow graph (CFG) is a representation of all instructions in a method, and the possible flow of execution through these instructions, it is used by many optimisations to reason about the possible behaviors of a method

- Nodes of the CFG represent the instructions to be executed. There is an edge from node $n_1$ to $n_2$ if $n_2$ could be executed immediately after $n_1$
- We add distringuised `ENTRY` and `EXIT` nodes representing the beginning and end of the method execution
- In Jimple, most instructions only have a single successor except conditional jumps, which has 2 (we ignore exceptions)

## Data Flow Analysis

Many analyses employed by compiler optimisations are data flow analyses: They gather information about the values computed and assigned to variables at different points in the program

- Data flow analyses work on the CFG, considering all possible paths from `ENTRY` node to a certain node, or from that node to the `EXIT` node
- A typical example of data flow analysis is **liveness** analysis, determining which local variables are live at what point in the program

## Liveness Analysis

- A local variable is live at a program point if its value may be read before it is reassigned
- In terms of a CFG, a variable `x` is live after a CFG node $n$ if there is a path $p$ from $n$ to `EXIT` such that there is another node $r$ on $p$ that reads `x`, and $r$ is not preceded on $p$ by any other node that writes to `x`
- A variables can be live before or after a node
- For some node $n$, we write $in_L(n)$ for the set of variables that are live **before** $n$, and $out_L(n)$ for the set of variables that are live after $n$. These sets are known as flow sets
- The goal of liveness analysis is to compute $in_L(n)$ and $out_L(n)$ for all CFG nodes

Note that, if we already known $out_L(n)$ for some node, $in_L(n)$ is easy to compute. A variable $x$ is live before $n$ if

1. Either $n$ reads $x$
2. Or $x$ is live after $n$ and $n$ does not write to $x$

By convention, the set of local variables a node $n$ reads is denoted as $use(n)$, and the set of variables it writes is $def(n)$. Hence, we have

$$
in_L(n) = out_L(n) - def(n) \cup use(n)
$$

The set of live variables going into $n$ is the set of live variables coming out of $n$, minus the variables written by $n$ (since $n$ overwrites these variables, these variables become dead), plus the variables read by $n$. This equation is known as the **transfer function** for $in_L(n)$

- A data flow analysis where $in_L(n)$ is computed from $out_L(n)$ is called a **backward flow analysis** - an analysis where $out_L(n)$ is computed from $in_L(n)$ is called **forward flow** analysis

How to compute $out_L(n)$? There are 2 cases

1. Node $n$ is the `EXIT` node: $out_L(n) = \emptyset$: No variables are live at the end of a method
2. Node $n$ has at least 1 successor node (There is more code to execute after $n$):
   - Let $succ(n)$ be the set of successor nodes of $n$
   - Note that a variable $x$ is live after $n$ if it is live before any successor of $n$
   - We then define $out_L(n) = \bigcup \{in_L(m) \ | \ m \in succ(n) \}$
   - The live variables coming out of $n$ is the union of all live variables going into all child nodes

A data flow analysis where union is used to combine results from successor nodes is called a **may** analysis: If intersection is used, the analysis is a **must** analysis

## Computing Transfer Functions

The system of equations for the transfer functions cannot be solved directly, because the definitions are circular. Howver, the equation system can be solved by iteration

1. For all nodes $n$, set $in_L(n) = out_L(n) = \emptyset$
2. For every node $n$, recompute $out_L(n)$ based on the values we have computed in the previous iteration, and then recompute $in_L(n)$ from $out_L(n)$
3. Keep repeating step 2 until values do not change any further

This algorithm terminates and computes a solution for the equation system (Proof of this result is beyond the scope of the course)

This method can be used for many other data flow analyses

## Simplifying Transfer Equations

To make it easier to solve these equations, we substitute $out_L(n)$ away, so we only have to solve for $in_L(n)$

## Common Subexpression Elimination

Useful optimisation: Identify expressions that have been computed before, and resuse the previously computed result

```
t = z*2; # computed first time
if t > y goto l2;
r = r*r;
z = z*2; # reused
```

Since the last `z*2` has been computed before, we replace it with the assignment `z = t`

slide 28
