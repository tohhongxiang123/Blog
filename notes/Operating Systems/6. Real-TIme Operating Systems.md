# Real-Time Operating Systems

What is a Real-Time Operating System (RTOS)?

An RTOS is an operating system intended to serve real-time applications that process data as it comes in, typically without buffer delays. Processing times for RTOS are usually measured in tenths of seconds or shorter increments of times

RTOS rapidly switch between tasks, giving the impression that multiple programs are being executed at the same time on a single processing core. However, the processing core can only execute one program at a time, but by rapidly switching between processes, it gives the impression that multiple programs are being executed simultaneously.

ROTS are used in:

- Automotive Systems (Autonomous driving, parking assistants)
- Avionics (Flight navigation and control)
- Manufacturing systems (Robotics, process controls) etc.

RTOS must be able to 
- Collect data from various sensors
- Execute control law(s) to determine response
- Send actuator commands in a **reasonable amount of time**
    - Actuators receive commands and perform actions based on the command

## What is a reasonable amount of time?

The response time of an RTOS is especially important, and depend on a few things

1. Functionality of RTOS
    - Collision avoidance (milliseconds)
    - Pacemaker (up to a second)
2. Environmental constraints
    - Available communication and computing resources
    - Timing characteristics of sensors/actuators/operations
3. Failure Mitigation Strategies
    - Time to detect and recover from failures
    - E.g. execution replication for redundancy

## A Common Misconception Regarding RTOS

Real-time does not mean fast, but **predictable even in worst-case**

# Definition of RTOS

> An RTOS is a system whose correctness not only depends on the logical/functional aspects, but the temporal aspects as well

Key performance indicators for RTOS include
- Timeliness, predictability on timing constraints (deadlines)
- Significance of worst-case vs average case

Deadlines are a function of application requirements (different requirements will result in different deadlines)

# Real-Time Process Specification

## Real-Time Process

> A real time process defined as $<R, C, D>$, where $R$ is the **process release time**, $C$ is the **execution requirement** (cost), and $D$ is the **relative deadline**

For the RTP, it requires $C$ time units of CPU in the interval $[R, R+D)$

## Real-Time Processes are Recurrent

Real-time processes collect data from sensors, execute control laws to determine responses, and send actuator commands in reasonable times. Recurrent real-time processes **repeat their processes regularly** (hence recurrent)

Each instance of execution of a recurrent real-time process is itself a single real-time process $<R, C, D>$

## Periodic Real-Time Process

Periodic real-time processes are processes that repeat themselves periodically at regular time intervals
- Process is generated by a t**ime-triggered phenomena** (e.g. sensor sending data periodically)
- E.g. perception function for detection collision

A periodic process is specified as $<T, C, D>$, where $T$ is a process period, and $C, D$ were defined earlier
- E.g. $P<10, 5, 7>$ means that process $P$ runs every 10 units of time, requires 5 units of time to complete, and has a relative deadline of +7 units of time after running

## Sporadic Real-Time Process

Sporadic real-time processes are processes that repeat themselves sporadically (at irregular time intervals), with a minimum time-gap between releases
- Process is generated by an **event-triggered phenomena**
- E.g. anti-lock braking function in automotives

A sporadic process is defined as $<T, C, D>$, where $T$ is the minimum separation time, and $C, D$ were defined earlier
- Real-time processes are released with a minimum gap of $T$

# Real-Time CPU Scheduling

Classic algorithms for CPU scheduling (such as FCFS, SJF, RR) fail in real-time CPU scheduling because they do not prioritise deadlines, hence perform poorly

Our problem statement is as follows:

> Given a set of periodic/sporadic real-time processes, find a uni-processor CPU scheduling algorithm that can meet all process deadlines

For real-time CPU scheduling, we have 2 classes of algorithms
1. Fixed priority CPU scheduling
2. Dynamic priority CPU scheduling

## Fixed Priority CPU Scheduling

For each recurrent process, the priorities for each instance of a process is fixed
- Consider 2 processes $P_0<10, 6, 10>$ and $P_1<19, 4, 19>$, and that $P_0$ has a higher priority than $P_1$
-  $P_0(R = 0)$ will have higher priority than $P_1(R = 0)$
-  $P_0(R = 10)$ will have higher priority than $P_1(R = 0)$
-  $P_0(R = 10)$ will have higher priority than $P_1(R = 19)$
-  etc.

For fixed priority scheduling, we have a few algorithms:
1. Rate-monotonic scheduler
2. Deadline-monotonic scheduler

### Rate-Monotonic (RM) Scheduler

Assign priorities based on process periods/minimum release-separation time (T)
- Shorter T, higher priority
- Ties are broken arbitrarily
- However, RM does not always prioritise urgent processes

## Deadline-Monotonic (DM) Scheduler

Assign priorities based on process deadlines (D)
- Shorter D, higher priority
- Ties are broken arbitrarily
- DM is usually better than RM, however because it cannot change priorities between instances, this sometimes causes deadline misses

## Dynamic Priority CPU Scheduling

Unlike fixed priority CPU scheduling, priorities for each instance of a process can change. 

For dynamic priority scheduling, we have the algorithm:
1. Earliest deadline first scheduler

### Earliest Deadline First (EDF) Scheduler

Instances with shorter deadline are given higher priority
- Whichever processes' deadline is the closest comes first
- Not the same as the parameter D
- Ties are broken arbitrarily

## RM/DM vs EDF

| RM/DM                                                              | EDF                                                                          |
| ------------------------------------------------------------------ | ---------------------------------------------------------------------------- |
| Simpler Implementation (separate queue for each recurrent process) | Harder implementation (Online sorting of queue, based on instance deadlines) |
| Predictability for high priority processes, even under overload    | Misbehavior during overload                                                  |

# Virtualisation

Virtualisation is a technique that uses a software called a Hypervisor (virtual machine manager, or VMM), to create an abstraction of hardware
- Hardware is divided into multiple virtual computers called **virtual machines**
- Each VM runs its own OS called **Guest OS**, and behaves like an independent computer
    - Application processes can run on a guest OS as if it is an independent computer
- Each VM uses only a portion of the actual hardware

## Functions of a Hypervisor

Creation and management of VMs
- Allocating hardware resources to VMs
- Executing instructions on the hardware on behalf of the VMs (VMs may be using different guest OSes)

Communication between VMs
- Mechanisms for VMs hosted on the same hardware to be able to communicate securely with each other

VM Migrations
- Migrating VMs from one hypervisor/hardware to another almost instantaneously (at runtime)
- Gives a lot of flexility and portability

## Why do we require virtualisation

Allows for more efficient utilisation of hardware
- Cost-effective hardware deployment and sharing
- Low latency and agile execution-environment deployments (VM creation and flexibility)
- Failure mitigation (VM independence and migrations)

Key technology that is driving cloud computing
- Cloud providers can dynamically and cost-effectively scale hardware allocations based on user requirements
- Enables the concept of platform-as-a-service - rent hardware and services as and when required

## Virtualisation Challenges

Requires management layer: Hypervisor
- Hypervisor is usually 2 orders of magnitude smaller than general purpose OSes
- Requires more disk space and RAM
- Must ensure that instructions can be executed on hardware

Real-time cyberphysical systems requires different solutions than server virtualisation
- Real-time (worst-case timing predictability)
- Must have minimal memory footprint and minimal overhead (highly resource constrained)

# Virtualisation Types

There are 2 different virtualisation techniques for hypervisors

![](https://miro.medium.com/max/1838/0*uOG3TpWM2BlBYkbg)

1. Type-1 Virtualisation
2. Type-2 Virtualisation

## Type-1 Virtualisation

Hypervisor interacts directly with hardware
- Also called bare-metal hypevisor
- Highly secure, low latency
- Popular in the industry (KVM, Microsoft Hyper-V, VMWare etc.)

## Type-2 Virtualisation

Hypervisor interacts with the host OS, which in turn interacts with hardware
- Also called hosted hypervisor
- Higher latency, less popular, mostly for end-user virtualisation (Oracle Virtualbox, VMWare Workstation)

## Virtualisation Levels

1. Full virtualisation
    - Complete abstraction of the actual hardware
    - Guest OS runs modified on the hypervisor
        - Guest OS is unaware of the hypervisor's existence
    - Example: Microsoft virtual server, VMWare exsi
2. Para-virtualisation
    - Unique software interface (API) between guest OS and VM
    - Guest OS needs to be modified to adapt to the new API
    - Advantage: VM does not need to virtualise hard-to-implement parts of the hardware instruction set, hence more efficient
    - Example: Xen, VMWare, XtratuM








