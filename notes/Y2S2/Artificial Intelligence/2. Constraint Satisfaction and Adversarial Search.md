# Constraint Satisfaction and Adversarial Search

# Constraint Satisfaction Problem (CSP)

Goal: Discover some state that satisfies a given set of constraints
- Minesweeper
- Sudoku

Goal test: A set of constraints specifying allowable combinations of values for subsets of variables

Let us consider the 8-queens problem. We want to find a way to place 8 queens on an 8x8 chessboard such that no queen attacks any other queen
- Variables: Locations of each of the 8 queens
- Values: Squares on the board
- Goal test: No 2 queens in the same row, column, diagonal

## Definitions in CSP

- A **state** of the problem is defined by **an assignment of values** to some or all of the variables
- An assignment that **does not violate any constraints** is called a **consistent** or **legal** assignment
- A **solution** to a CSP is **an assignment with every variable** given a value (complete) and the assignment **satisfies all given constraints**

## Applying Standard Search

- States: Defined by the values assigned so far
- Initial state: All variables unassigned
- Actions: Assign a value to an unassigned variable
- Goal test: All variables assigned, no constraints violated

How do we represent constraints?
- Either explicitly (D != E)
- Or implicitly (Use a function to test the state for constraint satisfaction)

## Backtracking Search

![Backtracking](https://ivoroshilin.files.wordpress.com/2015/02/backtrack.png)

- Do not waste time searching further if constraints are already violated
- Before generating successors (or expanding the search tree), check for constraint violations
- If yes, backtrack to try something else

## Heuristics for CSP

- Plain backtracking is an uninformed algorithm
- More intelligent searches take into consideration
    - Which variable to assign next
    - What order of the values to try for each variable
    - Implications of the current variable assignments for the other unassigned variables
        - Forward checking and constraint propagation
        - Constraint propagation: Propagating the implications of a constrain on one variable onto other variables

### Most Constraining Variable Heuristic

![Most constraining variable heuristic](https://slidetodoc.com/presentation_image/36dcd53781bcc9bff0881b2dd8d70db4/image-3.jpg)

Reduce the branching factor on future choices by selecting the variable that is involved in the largest number of constraints on unassigned variables
  
### Least Constraining Variable Heuristic

![Least constraining variable heuristic](https://slidetodoc.com/presentation_image_h/1ccd660e68faf6c6b26a516eb72c0c86/image-25.jpg)

Choose the value that leaves maximum flexibility for subsequent assignments

### Min-Conflicts Heuristic

![min conflicts heuristic](https://images.slideplayer.com/27/9196901/slides/slide_51.jpg)

Given an initial assignment, select a variable in the scope of the violated constraint, and assign it to the value that minimises the number of violated constraints

# Games as Search Problems

Abstraction
- Ideal representation of real world games
    - E.g. board games, chess, go etc. as an abstraction of war games
    - Perfect information (fully observable)
- Accurate formulation: State space representation

Uncertainty
- Account for the existence of hostile agents (players)
    - Other agents acting so as to diminish the agent's well-being
    - Uncertainty (about other agents' actions):
        - Not due to the effect of non-deterministic actions
        - Not due to randomness
            - Contingency problem

Complexity
- Games are abstract, but not simple
    - Chess has an average branching factor = 35, game length > 50
    - Complexity = $35^{50}$ (only $10^{40}$ for legal moves)
- Games are usually time limited
    - Complete search (for optimal solution) not possible
    - Uncertainty on current actions' desirability
    - Search efficiency is crucial

## Types of Games

|                       | Deterministic                | Chance                  |
| --------------------- | ---------------------------- | ----------------------- |
| Perfect Information   | Chess, Checkers, Go, Othello | Backgammon, Monopoly    |
| Imperfect Information |                              | Bridge, Poker, Scrabble |

- Initial state: Initial board configuration and indication of who makes the first move
- Operators: Legal moves
- Terminal test: Determines whether the game is over
    - States where the game has ended are terminal states
- Utility function (payoff function): Returns a numeric score to quantify the outcome of the game
    - E.g. Win (+1), Draw (0), Loss (-1)

## Minimax Search Strategy

- A search strategy that finds a sequence of moves that leads to a terminal state (goal)
- Aims to maximise one's own utility (make yourself win) and minimise the opponent's utility (make opponent lose)
- Assumption that the opponent does the same

Minimax is a 3 step process

1. Generate the entire game tree down to terminal states
2. Calculate utility
    - Assess utility of each terminal state (win, draw, loss)
    - Determine the best utility of the parents of the terminal state
    - Repeat the process for their parents until the root is reached
3. Select best move (move with highest utility value)

![Minimax search tree for tictactoe](https://www.researchgate.net/publication/262672371/figure/fig1/AS:393455625883662@1470818539933/Game-tree-for-Tic-Tac-Toe-game-using-MiniMax-algorithm.png)

We want to pick the move that maximises utility (win for current player). The algorithm is as follows:

```
function minimax(node, depth, maximizingPlayer) is
    if depth = 0 or node is a terminal node then
        return the heuristic value of node
    if maximizingPlayer then
        value := −∞
        for each child of node do
            value := max(value, minimax(child, depth − 1, FALSE))
        return value
    else (* minimizing player *)
        value := +∞
        for each child of node do
            value := min(value, minimax(child, depth − 1, TRUE))
        return value

(* Initial call *)
minimax(origin, depth, TRUE)
```

1. Expand entire game tree. Initialise each node to -infinity for maximising player, and +infinity for minimising player
2. Update values from bottom of search tree (terminal states) to the top (current state)
    1. For maximiser, we choose the node that maximises utility
    2. For minimiser, we choose teh node that minimises utility
3. Repeat until the top is reached
4. Player should then choose the move that gives the maximum utility

### Perfect Decisions by Minimax

- Perfect decisions can be made by minimax IF no time limit is imposed
    - Able to generate the complete search tree
- 2 players: MAX and MIN
    - Choose move with best achievable payoff against best play
    - MAX tries to maximise utility, assuming that MIN will try to minimise the player's utility

### Imperfect Decisions by Minimax

- For most games, such as chess, there are too many positions to exhaustively generate a search tree
    - Chess has branching factor = 35, each player makes about 50 moves. Hence the complete game tree requires $35^{100}$ positions
- Time/space requirements: Complete game tree search is impractical 
- Modifications made to minimax:
    1. Replace utility function by an estimated desirability of the position (Evaluation function)
    2. Partial tree search
        - E.g. depth limit
        - Replace terminal test by a cut-off test

#### Evaluation Functions

![Evaluation function for minimax](https://www.massey.ac.nz/~mjjohnso/notes/59302/fig05.04.gif)

Requirements
- Computation is efficient
- Agrees with utility function on terminal states
- Accurately reflects the chances of winning
- Trade off between accuracy and efficiency

An example for the evaluation function
- In othello, a piece in the corner is extermely helpful
- A piece on the border is more important than in the middle of the board
- Hence the heuristics can be as follows
    - Prioritise placing pieces on the borders/corners of the board
    - Add more to utility when a move made places a piece on the border
    - Add less utility when a move made places a piece in the center
    - Weighted sum based on the location of the pieces placed

### Quiescent Search

The evaluation function should only be applied to quiescent positions
- Positions that are not likely to have large variations in evaluation in thee near future
- If evaluation result is "volatile" (most likely will change a lot), then expand search
- If evaluation result is "quiet" (unlikely to change a lot), then do not need to expand search

```
function quiescence_search(node, depth) is
    if node appears quiet or node is a terminal node or depth = 0 then
        return estimated value of node
    else
        (recursively search node children with quiescence_search)
        return estimated value of children

function normal_search(node, depth) is
    if node is a terminal node then
        return estimated value of node
    else if depth = 0 then
        if node appears quiet then
            return estimated value of node
        else
            return estimated value from quiescence_search(node, reasonable_depth_value)
    else
        (recursively search node children with normal_search)
        return estimated value of children
```