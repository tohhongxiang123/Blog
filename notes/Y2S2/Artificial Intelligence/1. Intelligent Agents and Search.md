# Intelligent Agents and Search

An agent is an entity that
- perceives through sensors (eyes, ears, cameras etc)
- Acts through effectors (hands, legs, motors etc)

A rational agent is one that does the **right** thing
- Rational action: Action that maximises the expected value of an objective performance measure given the percept sequence to date
    - This means that a rational agent does an action that will most likely lead to the best outcome
- Rationality depends on:
    - Performance measure
    - Everything the agent has perceived so far
    - Built-in knowledge about the environment
    - Actions that can be performed

For example, a driverless taxi
- Percepts: Video, speed, acceleration, GPS etc.
- Actions: Steer, accelerate, brake, horn etc.
- Goals (Measure): Safety, reach destination, maximise profits, obey traffic laws, passenger comfort etc.
- Environment: Singapore urban streets, highways, traffic, pedestrians, weather, etc.

# Types of Environment

- Accessible vs Inaccessible
    - Agent's sensory apparatus give it access to the **complete** state of the environment
    - No portion of the environment is hidden from the agent
    - Accessible: An empty room whose state can be defined by its temperature. The agent can measure the temperature and know the complete state of the room
    - Inaccessible environment: Card-games. The player (agent) is unaware of the cards in the other player's hand
- Deterministic vs Non-deterministic
    - The next state of the environment is completely determined by the current state and the actions selected by the agent
    - No uncertainty in the environment for the agent
    - Deterministic environment: Traffic signal. Given the current signal, the pedestrian (agent) knows what the next signal is
    - Nondeterministic environment: Radio station. The listener (agent) is unaware about what the next song is
- Episodic vs Non-episodic
    - An episodic environment is where each episode is not affected by the previous taken actions
    - There is no link between the agent's performance and other different scenarios
    - This means that the agent will only consider the current task at hand, and **does not have to consider the effect it may have on future tasks**
    - Each state of the environment is independent of each other
    - Episodic environment: A support bot (agent) answering questions. Each question-answer is a single episode, and the questions answered previously has no effect on the agent's answers to future questions
    - Chess is a non-episodic environment. A move the agent chooses to do now may affect the decisions of the agent in the future
- Static vs dynamic
    - A static environment does not change while an agent is deliberating
    - Static environment: Empty office with no moving objects. While the agent is thinking about what to do, the environment does not change at all
    - Non-static environment: Physical world. While the agent is thinking about what to do, the world changes around it.
- Discrete vs continuous
    - A discrete environment has a limited number of distinct percepts and actions
    - Discrete environment: Checkers/chess, where there are only a set number of possible moves (Even though this set may be huge, it is still finite)
    - Continuous environment: Taxi driving. Infinite number of routes from anywhere to anywhere else

# Design of a Problem-solving Agent

Idea
- Systematically consider the expected outcomes of different possible sequences of actions that lead to states of known value
- Choose the best one
    - Shortest journey from A to B?
    - Most cost effective journey from A to B?

Steps:
1. Goal formulation: What objective do I want to achieve
2. Problem formulation: States, actions, check if goal is achieved
3. Solution: A sequence of legal actions being executed
4. Search: Algorithm for how to find a good solution
    - No knowledge: Uninformed search
    - Knowledge: Informed search

## Well-Defined Formulation

- Definition of the problem: Re-state the goal with more specification (Rules, resources etc)
- Formulation
    - Initial state
    - Action set: Set of available actions
    - State space: States reachable from initial state
        - Solution path: Sequence of actions from one state to another
    - Goal test predicate
        - Single state, enumerated list of states, abstract properties
    - Cost function
        - Path cost g(n), sum of all (action) step costs along the path
- Solution
    - A path (a sequence of operators leading) from the initial state to a state that satisfies the goal-test

## Measuring Problem-Solving Performance

- Search cost
    - What does it cost to find the solution?
        - How long to find the solution? How much resources used to find the solution?
- Total cost of problem-solving
    - Search cost (offline) + Execution cost (online)
    - Trade-offs are often required
        - Search a very long time for an optimal solution
        - Search a shorter time for a "good enough" solution

For example, 8 puzzle

![8 puzzle](https://miro.medium.com/max/281/1*IQ4oYMH3SCAriifZMdZA9w.png)

- State: Integer locations of the tiles (Total of 9! possible states)
- Actions: Move blank left, right, up, down
- Goal test: Goal state (given)
- Path cost: 1 per move

# Search Algorithms

- Exploration of state space by generating successors of already-explored states
    - Frontier: Candidate nodes for expansion
    - Explored set: Nodes already explored

## Search Strategies

- A strategy is defined by picking the order of node expansion
- Strategies are evaluated along the following dimensions
    1. Completeness: Does it always find a solution if one exists?
    2. Time complexity: How long does it take to find a solution?
    3. Space complexity: How much resources does it take to find a solution?
    4. Optimality: Does it always find the best (least-cost) solution?

### Uninformed vs Informed Search

Uninformed search strategies
- Use only information available in the problem definition
    - Breadth-first search
    - Uniform-cost search
    - Depth-first search
    - Depth-limited search
    - Iterative deepening search

Informed search strategies
- Use problem-specific knowledge to guide the search
- Usually more efficient

### Uninformed Searches

- Systematic generation of new states (test goal each time we reach a new state)
- Inefficient (Exponential space and time complexity)

#### Breadth First Search (BFS)

![Breadth first search](https://www.guru99.com/images/1/020820_0543_BreadthFirs1.png)

Expands shallowest unexpanded node. This strategy can be implemented with a first-in-first-out queue

Denote the following:
- $b$: Maximum branching factor of the search tree (Each node has $b$ children)
- $d$: Depth of the least-cost solution

BFS is
- Complete if $b$ is not infinite, because it visits all levels until the best solution is found
- Optimal only if all steps cost equally
    - If all steps do not cost equally, it is possible to have a solution that requires more depth to search, but costs less. BFS would have failed to find that solution, because it returns the solution with the minimum depth (not minimum cost)

Complexity of BFS
- Hypothetical state-space, where every node can be expanded into $b$ new nodes, solution of path-length $d$
- Time taken = $1 + b + b^2 + \cdots + b^d = O(b^d)$
- Space taken = If every node is kept in memory, $O(b^d)$

#### Uniform-cost Search (UCS)

To consider edge costs, expand unexpanded node with the least path cost $g$
- Modification of BFS
- Instead of FIFO queue, use priority queue with path cost $g(n)$ to order the elements
- BFS = UCS with g(n) = Depth(n)
- An example of uniform-cost search is dijsktra's algorithm for finding the shortest path
- UCS is used instead of BFS if path costs are not equal, but each action costs greater than a small positive value $\epsilon$

UCS is
- Complete as long as the cost of each step exceeds some small positive integer $\epsilon$, to prevent infinite loops
- Optimal because it always expands the node with the least cost path

Complexity of UCS
- Time taken = Number of nodes with a path cost < path cost of optimal solution
    - UCS only searches all nodes which cost less than the optimal solution, because once the optimal solution is found, it stops, and never explores any paths that cost more than the optimal solution
    - If we consider $C$ to be the cost of the optimal solution, and every action costs at least $\epsilon$, then the time complexity is $O(b^{C / \epsilon})$
- Space taken = Number of nodes with a path cost < path cost of optimal solution
    - Similarly to time taken, nodes that are kept in the priority queue are only the nodes whose paths cost less than the optimal solution
    - $O(b^{C / \epsilon})$

#### Depth-First Search (DFS)

DFS expands the deepest unexpanded node, which can be implemented by a Last-in-First-out (LIFO) stack, backtrack only when there is no more expansion. We use DFS instead of BFS if memory is a serious constraint, because **DFS uses a lot less memory than BFS**

Denote $m$ as the maximum depth of the state space

DFS is 
- Not complete for infinite-depth spaces, or finite-depth spaces with loops
    - If there is repeated state checking, then DFS is complete
- Complete for finite-depth spaces without loops
- DFS is not optimal because it keeps expanding the first node until it finds a solution, without worrying about the cost of the solution

Complexity of DFS
- Time complexity = $O(b^m)$. If solutions are dense, may be faster than breadth-first
- Space complexity = $O(bm)$, because it only stores the path from the root to the leaf node ($m$), and the siblings of each node in the path ($b$ nodes each, for a depth of $m$)
    - Compare this to the space complexity of BFS which is $O(b^d)$

#### Depth-limited search (DLS)

The unbounded tree problem that appears in DFS can be fixed by imposing a limit on the depth that DFS can reach. Now, loops and infinite depth problems can be solved. 

Denote $l$ as the depth limit, and $d$ as the depth of the optimal solution

DLS is
- Complete only if $l > d$. If not, solution can never be reached
- Not optimal, just like DFS. Consider DFS as DLS with $l = \infty$. DLS is not optimal even if $l > d$

Complexity of DLS
- Time complexity: $O(b^l)$
- Space complexity: $O(bl)$

#### Iterative Deepening Depth-First Search (IDS)

A search strategy that is a combination of DFS and BFS, combining the advantage of each strategy. IDS takes the completeness and optimality of BFS with the small memory requirements of DFS

IDS works by looking for the best search depth $d$, starting with a depth limit of 0, and then making a DFS. If the search fails, it increases the depth limit by 1, and retries DFS again with a new depth of 1, until depth $d$ where the goal is found

IDS is
- Complete like BFS, as long as $b$ is not infinite
- Optimal like BFS, when the steps are of the same cost

Complexity of IDS
- Time complexity = $O(b^d)$
- Space complexity = $O(bd)$

#### Bidrectional Search

![Bidirectional Search](https://i.imgur.com/w9XlrDR.png)

Runs 2 simultaneous searches - One from initial state, other from goal state. Search stops when they meet each other at some point in the middle of the graph

Bidirectional search is
- Complete when BFS is used in both searches
- Optimal when BFS is used in both searches, and the paths are of a uniform cost
- Note that other searches can be used, such as DFS. However, the choice of search used may lead to a sacrifice in completeness or optimality, or both.

Complexity of bidirectional search
- Time complexity = $O(b^{d/2})$
- Space complexity = $O(b^{d/2})$

### Summary

| Criterion | BFS   | UCS   | DFS   | DLS               | IDS   | Bidirectional |
| --------- | ----- | ----- | ----- | ----------------- | ----- | ------------- |
| Time      | $b^d$ | $b^d$ | $b^m$ | $b^l$             | $b^d$ | $b^{d/2}$     |
| Space     | $b^d$ | $b^d$ | $bm$  | $bl$              | $bd$  | $b^{d/2}$     |
| Optimal   | Yes   | Yes   | No    | No                | Yes   | Yes           |
| Complete  | Yes   | Yes   | No    | Yes if $l \geq d$ | Yes   | Yes           |

### Informed Searches

- Use problem-specific knowledge to decide the order of node expansion
- Best first search: Expand the "most desirable" unexpanded node
    - Use an **evaluation function** to estimate the desirability of each node

Evaluation function
- A path-cost function $g(n)$
    - Cost from initial state to current state (search-node) $n$
    - Information on the cost toward the goal is not required
- Heuristic function $h(n)$
    - Estimated cost of the cheapest path from $n$ to a goal state
    - Exact cost cannot be determined
    - Depends only on the state at that node (may not include history)
    - $h(n)$ is not larger than the real cost (admissible)
        - Admissible: Acceptable or valid
        - An admissible heuristic function will always underestimate the path cost to the goal, or provide a correct esimate for the path cost to the goal

#### Greedy Search

Expands the node that appears to be the closest to the goal
- Evaluation function: $h(n)$: Estimate of the cost from $n$ to the goal

For example, for finding the shortest path, we may always want to expand to the node that brings us to the closest straight line distance from the goal. Note how this heuristic function a problem-specific approach. 

Greedy search is
- Not complete. There is always a possibility that greedy search takes a path that does not bring it to the goal
- Not optimal. A path taken that is the best choice "currently" may not be the overall best choice

Complexity of greedy search
- Time complexity = $O(b^m)$
- Space complexity = $O(b^m)$ (keeps all nodes in memory)

#### A* Search

- UCS
    - $g(n)$: Cost to reach $n$ from the start (Past experience)
    - Optimal and complete, but can be inefficient
- Greedy search
    - $h(n)$: Cost from $n$ to goal (Future prediction)
    - Neither optimal nor complete, but cuts search space considerably

A* combines greedy search with uniform-cost serach together. Evaluation function is $f(n) = g(n) + h(n)$
- $f(n)$ is the estimated total cost of a path from the start, through $n$ to the goal
- If $g = 0$, then this is just a greedy search
- If $h = 0$, then this is just a uniform-cost search

A* is
- Optimal because the heuristic function is admissible (will always underestimates or is exactly correct)
- Complete if there are a finite number of nodes, because in the worst case A* will exhaustively search through all the nodes

Complexity of A*
- Time complexity = $O(b^m)$
- Space complexity: $O(b^m)$ (all generated nodes are kept in memory)
- With a good heuristic function, significant savings are possible compared to uninformed search methods

# Resources

- https://www.aitude.com/understand-types-of-environments-in-artificial-intelligence/
- https://mhesham.wordpress.com/tag/uniform-cost-search/